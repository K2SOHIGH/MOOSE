include: "rules/fun.smk"

from utils import sample
from utils import utils
from utils import assembly

wlogger = log.setlogger(__name__)
    
"""
    SETUP
"""

RESDIR = config["RESDIR"]
SAMPLES_DIR = "SAMPLES"

products = {
    "SRO": os.path.join(
        RESDIR, SAMPLES_DIR , "{sample}", "{assembly_type}" , "{assembler}" , "{file}" ),
    "SRF": os.path.join(
        RESDIR, SAMPLES_DIR , "{sample}", "{assembly_type}" , "{assembler}" , "{file}" ),
    "LRF": os.path.join(
        RESDIR, SAMPLES_DIR , "{sample}", "{assembly_type}" , "{assembler}" , "{file}" ),
    "bams":os.path.join(
        RESDIR , SAMPLES_DIR , "{sample}" , "{assembly_type}" , "{assembler}" , "BAMs" , "{mapper}.sorted.bam"),
}



SAMPLES = sample.Samples(config["INPUT"])

wlogger.info("Grabing configuration and input files =Â°")

wlogger.info("workflows choosen by user  : \n\t- {}".format("\n\t- ".join(config["WORKFLOWS"])))
wlogger.info("Assemblers choosen by user : \n\t- {}".format("\n\t- ".join(config["ASSEMBLERS"])) )

WORKFLOWS = assembly.setup_workflows(config["WORKFLOWS"],config["ASSEMBLERS"])


wlogger.info("Validating SAMPLE files and configuration ...")  
if assembly.validate_samples(SAMPLES,WORKFLOWS):
    wlogger.info("Number of sample(s) : {}".format(len(SAMPLES.samples)))
    wlogger.info("input files seems ok regarding workflows and assemblers")  
else:
    wlogger.error("one or more sample do not have the necessary file(s) \
        to be assemble through {} strategy and/or by {} assembler".format(
            ", ".join(config["WORKFLOWS"]), 
            ", ".join(config["ASSEMBLERS"])
        ))
    exit(-1)
    

SAMPLES.samples.update( 
    extend_with_coassembly() 
)

MAPPERS = parse_mappers()

READS = SAMPLES.sample2reads()    


if not READS:
    wlogger.error("Can't retrieve your reads :(")
    exit(-1)    

onstart:
    wlogger.info("Starting assembly WORKFLOW")
onerror:
    wlogger.error("an error occured during assembly WORKFLOW :(")


rule assembly:
    output:                
        os.path.join(RESDIR  ,"assembly_report.html"),  
        os.path.join(RESDIR  ,"assembly.yaml"),         
        os.path.join(RESDIR  ,"bams.yaml"),         
        os.path.join(RESDIR  ,"profiles.yaml"),      
    input:
        contigs = expand(
            os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "contigsfile.yaml"),
            sample = SAMPLES.samples,
        ),
        bams = expand(
            os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "bamsfile.yaml"),
            sample = SAMPLES.samples,
        ),
        profiles = expand(
            os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "profile.yaml"),
            sample = SAMPLES.samples,
        ),
        quasts = expand(
            os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "{qc_contigs}-contigs-qc", "report.html"),
            sample = SAMPLES.samples, qc_contigs = ["raw","filtered"],
        ), 
        stats = os.path.join(RESDIR, SAMPLES_DIR, "assembly.stats.tsv"),
    conda:
        "envs/multiqc.1.13.yaml"     
    params:
        multiqc_target = RESDIR,
        outdir = RESDIR,
        name = "assembly_report.html",
    shell:
        "cat {input.contigs} > {output[1]} ; "
        "cat {input.bams} > {output[2]} ; "  
        "cat {input.profiles} > {output[3]} ; " 
        "multiqc {params.multiqc_target} -d -dd 3 -o {params.outdir} -n {params.name} -f "


rule assembly_make_anvio_profile_file:
    output:
        temp(os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "profile.yaml")),
    input:
        bams = os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "bamsfile.yaml"),
        contigs = os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "contigsfile.yaml"),
    run:
        contigs = yaml.load(open(str(input.contigs)), Loader = yaml.SafeLoader)
        bams = yaml.load(open(str(input.bams)), Loader = yaml.SafeLoader)
        profiles_dict = {}
        for sample_id, sample_assembly in contigs.items():
            if sample_id not in profiles_dict:
                profiles_dict[sample_id] = {"fasta":sample_assembly,"bams":bams[sample_id] }
        yaml.dump( profiles_dict ,  open(str(output) , 'w' ) ),



rule assembly_make_anvio_bams_file:
    output:
        temp(os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "bamsfile.yaml")),
    input:
        get_mapping_products,         
    run:
        bams_dict = {}
        for fi in input:
            strategy, assembler, _ = os.path.dirname(fi).split("/")[-3:]
            a_id = "_".join([wildcards.sample , strategy, assembler ])
            if a_id not in bams_dict:
                bams_dict[a_id] = {}
            b_id = os.path.basename(fi).replace(".sorted.bam","")
            b_id = "_" .join([b_id,strategy,assembler])
            bams_dict[a_id][b_id] = os.path.abspath(fi)
        yaml.dump( bams_dict ,  open(str(output) , 'w' ) ),


rule assembly_make_anvio_contigs_file:
    output:
        temp(os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "contigsfile.yaml")),
    input:
        get_assembly_products,            
    run:
        assembly_dict = {}
        for fi in input:
            strategy, assembler = os.path.dirname(fi).split("/")[-2:]
            a_id = "_".join([wildcards.sample , strategy, assembler ])
            assembly_dict[a_id] = os.path.abspath(fi)
        yaml.dump( assembly_dict ,  open(str(output) , 'w' ) ),


rule assemby_stats:
    output:
        os.path.join(RESDIR, SAMPLES_DIR, "assembly.stats.tsv"),
    input:
        expand(
            os.path.join(RESDIR, SAMPLES_DIR, "{sample}" , "{qc_contigs}-stats", "assembly.stats.tsv"),
            sample = SAMPLES.samples,
            qc_contigs = ["raw","filtered"],
        )
    shell:
        "head -n 1 {input[0]} > {output} && tail -q -n +2 {input} > {output}"


rule assembly_filtering:
    """
        filter contigs below a certain size and reformat contigs names for anvi'o
    """
    output:
        contigs =os.path.join( 
            RESDIR , SAMPLES_DIR, "{sample}","{assembly_type}" , "{assembler}" ,  "final_assembly.fasta"
        ),
        tsv =  os.path.join(
            RESDIR, SAMPLES_DIR , "{sample}","{assembly_type}" , "{assembler}" , "contigs_table.tsv"
        ),
        txt =  os.path.join(
            RESDIR, SAMPLES_DIR , "{sample}","{assembly_type}" , "{assembler}" , "contigs_filterout.txt"
        ),
    input:
        os.path.join(RESDIR, SAMPLES_DIR , "{sample}","{assembly_type}" , "{assembler}" , "contigs.fa" )
    params: 
        min_contig_len = int(config["min_contig_length"]) if "min_contig_length" in config else 1000 ,
    run:
        contig = 0
        total_contigs = 0
        filter_out_contig = 0
        with open(str(output.tsv),"w") as tblout:
            with open(str(output.txt),'w') as txtout:
                with open(str(output.contigs),'w') as fastaout:
                    with open(str(input),'r') as streamin:
                        sequence = ""
                        for line in streamin.readlines():
                            if line.startswith(">"):
                                based_header = line.strip().replace(">","")
                                total_contigs += 1
                                if sequence:
                                    if len(sequence)>1000:#params.min_contig_len
                                        contigid = "c_{}".format(contig) 
                                        fastaout.write( ">{}\n".format(contigid) )
                                        fastaout.write( "{}\n".format(sequence) )                                    
                                        tblout.write( "{}\t{}\t{}\n".format( line[1:] , contigid , wildcards.sample) )
                                        contig+=1
                                        sequence = "" #reset sequence
                                    else:
                                        txtout.write("{}\n".format( based_header)) 
                                        filter_out_contig += 1
                            else:
                                sequence += line.strip()
                            

include: "./rules/bowtie2.smk"
include: "./rules/contigstats.smk"
include: "./rules/megahit.smk"
include: "./rules/spades.smk"
include: "./rules/unicycler.smk"
include: "./rules/miniasm.smk"
include: "./rules/reads_processing.smk"
