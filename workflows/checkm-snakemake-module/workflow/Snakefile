configfile: "config/config.yaml"

import os
import logging
import yaml
from scripts.snakeutils import * 
from utils import log


wlogger = log.setlogger(__name__)

def bins2batches(bins,batch_size=config["batch_size"]):    
    batches = {"batch-{}".format(x//batch_size):list(bins.keys())[x:x+batch_size] for x in range(0,len(bins.keys()),batch_size) if x <= len(bins.keys())}
    return batches

def validate_config():
    if config["CheckM_data"] is None or not os.path.isdir(config["CheckM_data"]):
        wlogger.error("Checkm datas are missing ! See u !")
        exit(-1)
    if config["taxonomy_wf"]:
        rank,taxon = config["taxonomy_wf"].split(";")
        config["taxonomy_wf"] = {"enable":True,"rank":rank,"taxon":taxon}                    
    else:
        config["taxonomy_wf"] = {"enable":False,"rank":None,"taxon":None}        
    return None
        

# config and input validation :
validate_config()
BINS = parse_input(config["genome_input"] , config["genome_extension"] )

if not BINS:
    wlogger.error("Can't retrieve your bins :( you might check your input or the genome extension.")
    exit(-1)    

# setup : 
RESDIR = config["res_dir"]
TMPDIR = config['res_dir'] + "/tmp"

os.makedirs(TMPDIR, exist_ok=True)
yaml.dump(config,  open( RESDIR + "/config.yaml","w") )

BATCHES = bins2batches(BINS)
wlogger.info("Number of batches : {}".format(len(BATCHES)) )
checkm_res = "lineage_wf"
rank = None
taxon = None
if config["taxonomy_wf"]["enable"]:
    checkm_res = "{}_{}_taxonomy_wf".format(config["taxonomy_wf"]["rank"],config["taxonomy_wf"]["taxon"])
    rank = config["taxonomy_wf"]["rank"]
    taxon = config["taxonomy_wf"]["taxon"]

# snakemake start : 
onsuccess:
    os.system('rm -rf %s' % TMPDIR)

rule target_checkm_statistics:
    input:
        expand(os.path.join(config["res_dir"],"tables","checkM_{table}.tsv"),table=["taxonomy","statistics_full","statistics"]),
    
rule expand_benchmark:
    output:                
        config["res_dir"] + "/benchmark.txt"
    input:
        qa_full = expand(config["res_dir"] + "/benchmarks/qa_full/{batch}.txt",batch=BATCHES.keys()),
        lineage = expand(config["res_dir"] + "/benchmarks/lineagewf/{batch}.txt",batch=BATCHES.keys()),
    params:
        benchmarkdir = config["res_dir"] + "/benchmarks/"
    shell:
        "head -n +1 {input.lineage[0]} | sed 's/$/\tSTEP/g' >> {output} &&"
        "tail -q -n +2 {input.qa_full} | sed 's/$/\talign/g' >> {output} && "
        "tail -q -n +2 {input.lineage} | sed 's/$/\tidentify/g' >> {output} && "
        "rm -r {params.benchmarkdir}"


rule concat_tables:
    output:
        protected(os.path.join(config["res_dir"],"tables","checkM_{table}.tsv"))
    input:
        expand(os.path.join(TMPDIR,"{batch}",checkm_res,"checkM_{{table}}.tsv"),batch=BATCHES.keys())
    params:
        first = lambda wildcards, input: input[0],      
        tmpdir = TMPDIR,
    shell:
        "head -n 1 {params.first} > {output} && "
        "tail -q -n +2 {input} >> {output} "#&& rm -rf {params.tmpdir}"

rule checkM_taxonomy:
    """ Create an extended taxonomy. """
    output:
        tsv = os.path.join(TMPDIR, "{batch}", checkm_res ,"checkM_taxonomy.tsv"),
    input:
        tsv = os.path.join(TMPDIR, "{batch}", checkm_res ,"checkM_statistics.tsv"),
    conda: 
        os.path.join("envs","checkm.yaml")
    params:
        checkm_dir = lambda wildcards, output: os.path.dirname(output.tsv),
        checkm_data = config["CheckM_data"],
    log:
        os.path.join(config['res_dir'], 'logs', "{batch}", checkm_res , "taxonomy.log")
    shell:
        "echo \"{params.checkm_data}\" | checkm data setRoot {params.checkm_data} &> {log}; "
        "checkm tree_qa "
        "--tab_table "              # output as tab-separated file
        "-f {output.tsv} "          # output filename
        "{params.checkm_dir} "      # output folder
        "&>> {log} "

rule checkM_qa_full:
    """ Create an extended output with more statistics based on previous
    computation.
    
    It only uses `checkm qa` so it will be fast and not recompute everything.

    """
    output:
        tsv = os.path.join(TMPDIR,"{batch}",checkm_res , "checkM_statistics_full.tsv"),
    input:
        tsv = os.path.join(TMPDIR, "{batch}",checkm_res , "checkM_statistics.tsv"),
    conda: 
        os.path.join("envs","checkm.yaml")
    threads: 
        10
    params:
        checkm_dir = lambda wildcards, output: os.path.dirname(output.tsv),
        checkm_data = config["CheckM_data"],
    log:
        os.path.join(config['res_dir'], 'logs', "{batch}", checkm_res , "stats_full.log")
    benchmark:
        config["res_dir"] + "/benchmarks/qa_full/{batch}.txt"    
    shell:
        "echo \"{params.checkm_data}\" | checkm data setRoot {params.checkm_data} &>> {log};"
        "checkm qa "
        "-o 2 "                             # extended summary of bin stats
        "--tab_table "                      # output as tab-separated file
        "-f {output.tsv} "                  # output filename
        "-t {threads} "
        "{params.checkm_dir}/lineage.ms "   # <marker file>
        "{params.checkm_dir} "              # <output folder>
        "&>> {log} "


def get_bins(wildcards):
    bins = expand(os.path.join(TMPDIR,"Bins",wildcards.batch,"{bin}.fna"), bin=  BATCHES[wildcards.batch],)
    return bins


rule checkM_taxonomy_wf:
    """ Main checkM rule.
        Compute CheckM on a given batch of bins.

        phylum :Cyanobacteria              
        genomes : 129 
        marker genes : 472
        marker sets : 368

    """
    output:
        tsv = os.path.join(TMPDIR, "{batch}","%s_%s_taxonomy_wf" % (rank,taxon), "checkM_statistics.tsv"),
    input:
        # Function that returns the locations of genomes associated with {batch}        
        get_bins,
    conda: 
        os.path.join("envs","checkm.yaml")
    resources:
        mem= 16000 if config["low_memory"] else 50000,
        mem_mb= 20000 if config["low_memory"] else 70000,
        # time= 24:00:00, # time limit for each job
        nodes= 1,
        #cpus_per_task = 2 if config["low_memory"] else  5 ,    
        cpus_per_task = 10 if config["low_memory"] else  15 ,              
    threads: 
        10
    params:            
        checkm_dir = lambda wildcards, output: os.path.dirname(output.tsv),
        checkm_data = config["CheckM_data"],
        batch_dir = lambda wildcards, input: os.path.dirname(input[0]),
        rank = rank,
        taxon = taxon,
        tmp = "--tmpdir %s" % config["TMP"] if config["TMP"] else "",
    log:
        os.path.join(config['res_dir'], 'logs', "{batch}", checkm_res , "taxonomy_wf.log")
    shell:
        "echo \"{params.checkm_data}\" | checkm data setRoot {params.checkm_data} &>> {log}; "
        "checkm taxonomy_wf "
        "{params.rank} "
        "{params.taxon} "
        "{params.batch_dir} " # (input) directory containing the bin files
        "{params.checkm_dir} "          # (output) directory where to store the results
        "--tab_table "          # output as a tab-separated file
        "-f {output.tsv} "      # filename for the output
        "{params.tmp} "
        "-t {threads} "
        "-x fna "             # extension of the bin files
        "&>> {log} "

rule checkM_lineage_wf:
    """ Main checkM rule.
        Compute CheckM on a given batch of bins.
    """
    output:
        tsv = os.path.join(TMPDIR, "{batch}","lineage_wf","checkM_statistics.tsv"),
    input:
        # Function that returns the locations of genomes associated with {batch}        
        get_bins,
    conda: 
        os.path.join("envs","checkm.yaml")
    resources:
        mem= 16000 if config["low_memory"] else 50000,
        mem_mb= 20000 if config["low_memory"] else 70000,
        # time= 24:00:00, # time limit for each job
        nodes= 1,
        cpus_per_task = 10 if config["low_memory"] else  15 ,           
    threads: 
        10
    params:            
        checkm_dir = lambda wildcards, output: os.path.dirname(output.tsv),
        checkm_data = config["CheckM_data"],
        batch_dir = lambda wildcards, input: os.path.dirname(input[0]),
        low_memory = "--reduced_tree" if config["low_memory"] else "",
        tmp = "--tmpdir %s" % config["TMP"] if config["TMP"] else "",
    log:
        os.path.join(config['res_dir'], 'logs', "{batch}", checkm_res , "lineage_wf.log")
    benchmark:
        config["res_dir"] + "/benchmarks/lineagewf/{batch}.txt"    
    shell:
        "echo {params.checkm_data}; export LC_ALL=C : "
        "checkm data setRoot {params.checkm_data} &>> {log}; "
        "checkm lineage_wf "
        "--tab_table "          # output as a tab-separated file
        "-f {output.tsv} "      # filename for the output
        "-t {threads} "
        "{params.tmp} "
        "{params.low_memory} "
        "-x fna "             # extension of the bin files
        "{params.batch_dir}/ " # (input) directory containing the bin files
        "{params.checkm_dir} "  # (output) directory where to store the results
        "&>> {log} "

rule gunzip_bins_into_batches:
    """ Gunzip a `fasta.gz` into the appropriate batch directory. """
    output:
        temp(os.path.join(TMPDIR, 'Bins', '{batch}', '{bin}.fna'))
    input:
        bins = lambda wildcards: BINS[wildcards.bin]
    threads: 
        1 
    shell:
        'if [[ {input.bins} == *.gz ]] ; then '
        'gunzip -c {input.bins}  > {output} ; '
        'else '
        'cat {input.bins}  > {output} ; '
        'fi '        

